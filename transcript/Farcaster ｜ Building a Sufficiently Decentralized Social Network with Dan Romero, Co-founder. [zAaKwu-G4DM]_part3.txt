sharing it to everyone else, because it's relevant for people using it, it just starts to create some momentum where now other people are like, oh, interesting, this is something, if I'm spending time on Farcaster, this is a way I can actually kind of do something fun, but also get some status on this network, because this network is about like actually building on top of what's available. And so we've had a huge increase in the amount of developer activity over the last six to nine months. And we think it is going to hopefully increase even more once hubs are up. So these are all people who are trusting everything that I'm saying, which I'm appreciative that they are, but I don't think that that is good enough to be a protocol, like you need to hit some level of just don't, you know, trust the code, trust the ability for you to actually be completely sovereign without having to talk to anyone. And so where we are putting a lot of effort is to get hubs out. But then once hubs are out, I think we probably will shift towards maybe doing a little bit better job of documenting how to build things on Farcaster, giving people ideas, open source libraries that make it easier to do that. But I think doing all that now would just kind of be like, okay, yeah, you're getting more developer activity, but you're getting developer activity before you've actually done the hard thing of like showing that the system can actually work in a permissionless and decentralized way. That's good. So as we start turning the corner here, did we miss anything here? Is there anything we should talk about Farcaster? Anything about like what you're building now? Anything about like what you're really excited about in the next couple of weeks or a couple of months? Well, I've already talked about hubs. I think the one other thing that people bring up on decentralized social media, which I think is a reasonable point is how do you do content moderation? And my answer to them is, how do we do content moderation on the email protocol today? And then the second question would be, how do you do content moderation on the web? So to go through each of those examples on the email network, content moderation is done at the client level, right? So for those at home, client is kind of like the app that you use to access a protocol. So if you're using Gmail as your Gmail email address provider, that's your email client. And what's interesting about email is you can actually use one service for the like cloud-based stuff. So you can use Gmail where like your email lives in the cloud, but you don't necessarily have to use the Gmail app. There's another thing called IMAP, which is another protocol that allows you to use maybe the default mail client on an iPhone and connect in or Microsoft Outlook can connect into Gmail. So email is actually, you know, kind of like a lot of client choice. But how do you prevent bad actors from sending you email is we have spam filters. And so spam filters aren't a globally administered, there isn't a room where people are deciding what is spam versus not. It's done at a client level. Yes, they probably share, you know, block lists and things like that between the big providers, but ultimately Gmail's spam policy can be different than Microsoft's. That's a market-based decision. The web is a little different in that if you think about a browser, browser doesn't do any content moderation. I can go to basically any URL that's sent to me with the exception of the SSL certificate is out of whack. Chrome or Safari gets pretty aggressive and says, don't go to this web page, but you can still actually a lot of times click the advanced button and then still proceed. So web browsers actually have a lot more freedom in terms of like what you're able to access. And I think any reasonable person is not holding a web browser liable that if you end up on some website that whether it has hate speech or illegal content or whatever, the browser is not the issue here. It's actually the server that's hosting that website. And so the way this all works on the internet or like, you know, the web is most people use Google to navigate the web, right? Or a search engine and search engine makes no guarantee that they're going to index your page. In fact, they can de-index you and then there is no arbitration. You can't go to court. It's centralized in the sense that they can make those decisions based on what they think is the right user experience and following the rules in the country that they're in. But what's important is even though Google has what 90% market share, you know, they claim 60, but whatever, it's a massive amount of market share in search. You can use Bing, you can use DuckDuckGo, maybe ChatGPT will have a search engine later this year. Like, so that market is competitive in the sense that if Google got too crazy moderating, like by taking too many websites out of its index, people would switch to something different, right? So they have a natural check and balance on what's in their index. And, but the important thing though, is if they de-index you, you basically get no distribution. Yeah, you can share a link to your email subscriber list. But if you, you know, you have something where, I don't know, you have a website on the COVID vaccine and you want to get that information out there, even if a whole bunch of people link to you all over the internet, and that normally would make you rank high on Google if Google de-indexes you, just you don't exist. And so you're not going to get the traffic there. And so that people think is reasonable. It's like, well, Google can do that. So same thing happens with Farcaster, just like Spam or just like a Google search index, clients are going to decide what their content moderation policies are. So in the case of our client, we're a US-based company. We have regulations that we have to follow section 230, DMCA. So, you know, IP related stuff, but we also have the first amendment. So there is actually a balance there. And so I think for us, we're going to follow the letter of the law in the US. We're going to be transparent about it. But what's key is maybe those rules don't apply to someone who lives in France or someone who lives in Nigeria. And if someone wants to use a client that's respecting the rules in that country or use the protocol, they're free to do that. And I think that works on Ethereum. It works on the web where you actually have the freedom of choice of what client and what set of rules you want to play by. I think that Farcaster, as a protocol, would probably spend a lot more time being kind of focused on anti-spam, anti-anything that's like trying to harm the performance of the network. And the clients will do the work on is this content legal? Should this content get boosted in algorithm, etc.? But that will be much similar to email or search engine than what we traditionally think of social media, which I think the challenge with traditional social media and content moderation is your identity is bundled there with the posts, with the algorithm, with all of the distribution and engagement. And so you can't break apart pieces and say, OK, well, we're not going to host this content, but people can still interact with it. And actually, Macedon has a similar thing, by the way, where you can actually have other servers ban your server, which is interesting because if you're using a Macedon client and you're connecting into your Macedon server, you actually, even though the client might actually allow you to see content, your server where your identity is tied to might have a set of rules that's different. So I actually don't think that that gives much consumer choice. And so I think I want to get to a place where the content is separated from the client and you choose to host it. I want to get to a place where the content is separated from the client and you choose the client that works best for you. And the clients are also going to choose the level of risk tolerance that they want. And I actually fully expect most large clients in the forecaster network will have as much content moderation, maybe even in cases more than traditional social networks, because the important thing is that you're not censoring people. What you're just saying is, if you don't want to have content in our client, go somewhere else. And last point I'll give here is we lived with this at Coinbase. So Coinbase has something called a MAC, a mandatory account closure. You have to close an account because they're suspected of doing something illegal or fraudulent or just don't want to be a customer anymore. By the way, banks have this as well. When we did a MAC for a customer that had 10 Bitcoin with us, we don't keep the Bitcoin. We say, OK, sorry, we're no longer wanting to do business with you. Please tell us where to sign a Bitcoin. That's it. And like that, to me, is a much more reasonable approach to saying, we don't want to do business with you. That's fine. But we're not censoring you. We're not disappearing you off the Internet. We're not taking your audience away. That should be left to, in my opinion, the true legality of where the Web's content is hosted. And if that person is actually doing things that are illegal, it's going to catch up with them at some point. And I think that that is a healthier ecosystem because then you don't have some one company and one team trying to decide what is truth or what is good or bad. It's no, we have our set of policies and we have our set of rules and this is the way it works. We ask of all of our guests, because we have a diverse audience that's seeking to learn and as we say, go from crypto curious to crypto native. So we always like to learn what is it that inspired you, that motivated you early on in your crypto career? Was it something you read, someone, a blog on Twitter, for instance? What was that? I think the initial inspiration for me working in tech is I kind of fell in love with blogs on the Internet and I just thought it was so cool that for not a lot of money and not a lot of effort, you could be online and start publishing. And if people found your stuff interesting, you could grow an audience, right? There's no gatekeeper effectively. And so I've always kind of been really into that. I think Paul Graham's essays were pretty influential as well. I think about them a lot. I never did YC, my co-founder Varun actually had a company in YC prior to working at Coinbase. But I think as an entrepreneur, I kind of run through a lot of these challenges on a regular basis and I find myself going back to kind of these little truisms that Paul Graham has, do things that don't scale. Find 100 users that love your product rather than 10,000 users or 100,000 users that like your product. And I think the ethos of what PG has put online and the kind of like what YC, especially in the early days, stood for this idea that like, no, there should be more people trying to build new things in the world, like ambitious new things. I think it's been like something that I've been really into probably since I was in high school. And so that's kind of both in working at Coinbase, which was exciting, but then in starting Farcaster, I think I'm just generally inspired to, I don't know, put a dent in the universe and work on something that I believe in the long run kind of enables forward progress, right? Like civilizational progress. And that's a wrap. If you'd like to learn more about Dan Romero and Farcaster, you can follow them on Twitter at DWR and Farcaster underscore XYZ, respectively. And please don't forget to give us a like, subscribe, and a five-star review wherever you listen to this podcast. It really means a lot to us and it helps this content get to more people like you. And if you want to catch more episodes like this one, go to our website at cryptosapiens.xyz. Until next time, stay brainy.